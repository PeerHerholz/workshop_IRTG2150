{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to `pybids`\n",
    "\n",
    "[`pybids`](https://github.com/bids-standard/pybids) is a tool to query, summarize and manipulate data using the [BIDS](https://bids-specification.readthedocs.io/en/stable/) standard. In this tutorial we will use `pybids` on a test `dataset` to illustrate some of the functionality of `pybids.layout`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:05:23.628184Z",
     "start_time": "2018-08-01T20:05:22.060937Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bids import BIDSLayout\n",
    "from bids.tests import get_test_data_path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `BIDSLayout`\n",
    "\n",
    "At the core of `pybids` is the `BIDSLayout` object. A `BIDSLayout` is a lightweight `Python class` that represents a `BIDS` project file tree and provides a variety of helpful methods for querying and manipulating `BIDS` files. While the `BIDSLayout` initializer has a large number of `arguments` you can use to control the way files are indexed and accessed, you will most commonly initialize a `BIDSLayout` by passing in the `BIDS` dataset root location as a single `argument`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:05:23.739377Z",
     "start_time": "2018-08-01T20:05:23.630505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BIDS Layout: ...advanced/../data/pybids_7t_trt | Subjects: 10 | Sessions: 20 | Runs: 20"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we're using an example BIDS dataset that's bundled with the pybids tests\n",
    "# Initialize the layout\n",
    "layout = BIDSLayout('../data/pybids_7t_trt/')\n",
    "\n",
    "# Print some basic information about the layout\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the `BIDSLayout`\n",
    "When we initialize a `BIDSLayout`, all of the files and `metadata` found under the specified root folder are indexed. This can take a few seconds (or, for very large `datasets`, a minute or two). Once initialization is complete, we can start querying the `BIDSLayout` in various ways. The workhorse method is [`.get()`](https://bids-standard.github.io/pybids/generated/bids.grabbids.BIDSLayout.html#bids.grabbids.BIDSLayout.get). If we call `.get()` with no additional `arguments`, we get back a list of all the `BIDS` files in our `dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 339 files in the layout.\n",
      "\n",
      "The first 10 files are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<BIDSJSONFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/dataset_description.json'>,\n",
       " <BIDSDataFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/participants.tsv'>,\n",
       " <BIDSFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/README'>,\n",
       " <BIDSImageFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/anat/sub-01_ses-1_T1map.nii.gz'>,\n",
       " <BIDSImageFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/anat/sub-01_ses-1_T1w.nii.gz'>,\n",
       " <BIDSImageFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/fmap/sub-01_ses-1_run-1_magnitude1.nii.gz'>,\n",
       " <BIDSImageFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/fmap/sub-01_ses-1_run-1_magnitude2.nii.gz'>,\n",
       " <BIDSJSONFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/fmap/sub-01_ses-1_run-1_phasediff.json'>,\n",
       " <BIDSImageFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/fmap/sub-01_ses-1_run-1_phasediff.nii.gz'>,\n",
       " <BIDSImageFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/fmap/sub-01_ses-1_run-2_magnitude1.nii.gz'>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = layout.get()\n",
    "\n",
    "print(\"There are {} files in the layout.\".format(len(all_files)))\n",
    "print(\"\\nThe first 10 files are:\")\n",
    "\n",
    "all_files[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned object is a `Python list`. By default, each element in the `list` is a `BIDSFile` `object`. We discuss the `BIDSFile` object in much more detail below. For now, let's simplify things and work with just filenames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/dataset_description.json',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/participants.tsv',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/README',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/anat/sub-01_ses-1_T1map.nii.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/anat/sub-01_ses-1_T1w.nii.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/fmap/sub-01_ses-1_run-1_magnitude1.nii.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/fmap/sub-01_ses-1_run-1_magnitude2.nii.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/fmap/sub-01_ses-1_run-1_phasediff.json',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/fmap/sub-01_ses-1_run-1_phasediff.nii.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/fmap/sub-01_ses-1_run-2_magnitude1.nii.gz']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.get(return_type='filename')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.get_subjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rest']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.get_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': <Entity subject (pattern=[/\\\\]+sub-([a-zA-Z0-9]+), dtype=<class 'str'>)>,\n",
       " 'session': <Entity session (pattern=[_/\\\\]+ses-([a-zA-Z0-9]+), dtype=<class 'str'>)>,\n",
       " 'sample': <Entity sample (pattern=[_/\\\\]+sample-([a-zA-Z0-9]+), dtype=<class 'str'>)>,\n",
       " 'task': <Entity task (pattern=[_/\\\\]+task-([a-zA-Z0-9]+), dtype=<class 'str'>)>,\n",
       " 'tracksys': <Entity tracksys (pattern=[_/\\\\]+tracksys-([a-zA-Z0-9]+), dtype=<class 'str'>)>,\n",
       " 'acquisition': <Entity acquisition (pattern=[_/\\\\]+acq-([a-zA-Z0-9]+), dtype=<class 'str'>)>,\n",
       " 'nucleus': <Entity nucleus (pattern=[_/\\\\]+nuc-([a-zA-Z0-9]+), dtype=<class 'str'>)>,\n",
       " 'volume': <Entity volume (pattern=[_/\\\\]+voi-([a-zA-Z0-9]+), dtype=<class 'str'>)>,\n",
       " 'ceagent': <Entity ceagent (pattern=[_/\\\\]+ce-([a-zA-Z0-9]+), dtype=<class 'str'>)>,\n",
       " 'staining': <Entity staining (pattern=[_/\\\\]+stain-([a-zA-Z0-9]+), dtype=<class 'str'>)>,\n",
       " 'tracer': <Entity tracer (pattern=[_/\\\\]+trc-([a-zA-Z0-9]+), dtype=<class 'str'>)>,\n",
       " 'reconstruction': <Entity reconstruction (pattern=[_/\\\\]+rec-([a-zA-Z0-9]+), dtype=<class 'str'>)>,\n",
       " 'direction': <Entity direction (pattern=[_/\\\\]+dir-([a-zA-Z0-9]+), dtype=<class 'str'>)>,\n",
       " 'run': <Entity run (pattern=[_/\\\\]+run-(\\d+), dtype=<class 'bids.layout.utils.PaddedInt'>)>,\n",
       " 'proc': <Entity proc (pattern=[_/\\\\]+proc-([a-zA-Z0-9]+), dtype=<class 'str'>)>,\n",
       " 'modality': <Entity modality (pattern=[_/\\\\]+mod-([a-zA-Z0-9]+), dtype=<class 'str'>)>,\n",
       " 'echo': <Entity echo (pattern=[_/\\\\]+echo-([0-9]+), dtype=<class 'str'>)>,\n",
       " 'flip': <Entity flip (pattern=[_/\\\\]+flip-([0-9]+), dtype=<class 'str'>)>,\n",
       " 'inv': <Entity inv (pattern=[_/\\\\]+inv-([0-9]+), dtype=<class 'str'>)>,\n",
       " 'mt': <Entity mt (pattern=[_/\\\\]+mt-(on|off), dtype=<class 'str'>)>,\n",
       " 'part': <Entity part (pattern=[_/\\\\]+part-(imag|mag|phase|real), dtype=<class 'str'>)>,\n",
       " 'recording': <Entity recording (pattern=[_/\\\\]+recording-([a-zA-Z0-9]+), dtype=<class 'str'>)>,\n",
       " 'space': <Entity space (pattern=[_/\\\\]+space-([a-zA-Z0-9]+), dtype=<class 'str'>)>,\n",
       " 'chunk': <Entity chunk (pattern=[_/\\\\]+chunk-([0-9]+), dtype=<class 'str'>)>,\n",
       " 'suffix': <Entity suffix (pattern=(?:^|[_/\\\\])([a-zA-Z0-9]+)\\.[^/\\\\]+$, dtype=<class 'str'>)>,\n",
       " 'scans': <Entity scans (pattern=(.*\\_scans.tsv)$, dtype=<class 'str'>)>,\n",
       " 'fmap': <Entity fmap (pattern=(phasediff|magnitude[1-2]|phase[1-2]|fieldmap|epi)\\.nii, dtype=<class 'str'>)>,\n",
       " 'datatype': <Entity datatype (pattern=[/\\\\]+(anat|beh|dwi|eeg|fmap|func|ieeg|meg|micr|motion|mrs|nirs|perf|pet)[/\\\\]+, dtype=<class 'str'>)>,\n",
       " 'extension': <Entity extension (pattern=[^./\\\\](\\.[^/\\\\]+)$, dtype=<class 'str'>)>,\n",
       " 'EchoTime2': <Entity EchoTime2 (pattern=None, dtype=<class 'str'>)>,\n",
       " 'EchoTime1': <Entity EchoTime1 (pattern=None, dtype=<class 'str'>)>,\n",
       " 'IntendedFor': <Entity IntendedFor (pattern=None, dtype=<class 'str'>)>,\n",
       " 'CogAtlasID': <Entity CogAtlasID (pattern=None, dtype=<class 'str'>)>,\n",
       " 'EchoTime': <Entity EchoTime (pattern=None, dtype=<class 'str'>)>,\n",
       " 'EffectiveEchoSpacing': <Entity EffectiveEchoSpacing (pattern=None, dtype=<class 'str'>)>,\n",
       " 'MTState': <Entity MTState (pattern=None, dtype=<class 'str'>)>,\n",
       " 'PhaseEncodingDirection': <Entity PhaseEncodingDirection (pattern=None, dtype=<class 'str'>)>,\n",
       " 'RepetitionTime': <Entity RepetitionTime (pattern=None, dtype=<class 'str'>)>,\n",
       " 'SliceEncodingDirection': <Entity SliceEncodingDirection (pattern=None, dtype=<class 'str'>)>,\n",
       " 'SliceTiming': <Entity SliceTiming (pattern=None, dtype=<class 'str'>)>,\n",
       " 'TaskName': <Entity TaskName (pattern=None, dtype=<class 'str'>)>,\n",
       " 'StartTime': <Entity StartTime (pattern=None, dtype=<class 'str'>)>,\n",
       " 'SamplingFrequency': <Entity SamplingFrequency (pattern=None, dtype=<class 'str'>)>,\n",
       " 'Columns': <Entity Columns (pattern=None, dtype=<class 'str'>)>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.get_entities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering files by entities\n",
    "\n",
    "The utility of the `BIDSLayout` would be pretty limited if all we could do was retrieve a `list` of all files in the `dataset`. Fortunately, the `.get()` method accepts all kinds of arguments that allow us to filter the result set based on specified criteria. In fact, we can pass *any* `BIDS`-defined keywords (or, as they're called in `PyBIDS`, *entities*) as constraints. For example, here's how we would retrieve all `BOLD` runs with `.nii.gz` extensions for `participant` '`01`':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/func/sub-01_ses-1_task-rest_acq-fullbrain_run-1_bold.nii.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/func/sub-01_ses-1_task-rest_acq-fullbrain_run-2_bold.nii.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/func/sub-01_ses-1_task-rest_acq-prefrontal_bold.nii.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-2/func/sub-01_ses-2_task-rest_acq-fullbrain_run-1_bold.nii.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-2/func/sub-01_ses-2_task-rest_acq-fullbrain_run-2_bold.nii.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-2/func/sub-01_ses-2_task-rest_acq-prefrontal_bold.nii.gz']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.get(subject='01', extension='nii.gz', suffix='bold', return_type='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-02/ses-1/func/sub-02_ses-1_task-rest_acq-fullbrain_run-1_bold.nii.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-02/ses-1/func/sub-02_ses-1_task-rest_acq-fullbrain_run-1_physio.tsv.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-02/ses-1/func/sub-02_ses-1_task-rest_acq-fullbrain_run-2_bold.nii.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-02/ses-1/func/sub-02_ses-1_task-rest_acq-fullbrain_run-2_physio.tsv.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-02/ses-1/func/sub-02_ses-1_task-rest_acq-prefrontal_bold.nii.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-02/ses-1/func/sub-02_ses-1_task-rest_acq-prefrontal_physio.tsv.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-02/ses-2/func/sub-02_ses-2_task-rest_acq-fullbrain_run-1_bold.nii.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-02/ses-2/func/sub-02_ses-2_task-rest_acq-fullbrain_run-1_physio.tsv.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-02/ses-2/func/sub-02_ses-2_task-rest_acq-fullbrain_run-2_bold.nii.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-02/ses-2/func/sub-02_ses-2_task-rest_acq-fullbrain_run-2_physio.tsv.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-02/ses-2/func/sub-02_ses-2_task-rest_acq-prefrontal_bold.nii.gz',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-02/ses-2/func/sub-02_ses-2_task-rest_acq-prefrontal_physio.tsv.gz']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.get(subject='02', return_type='file', task=\"rest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're wondering what entities you can pass in as filtering arguments, the answer is contained in the .json configuration files [housed here](https://github.com/bids-standard/pybids/tree/master/bids/layout/config). To save you the trouble, here are a few of the most common entities:\n",
    "\n",
    "* `suffix`: The part of a `BIDS` filename just before the extension (e.g., '`bold`', '`events`', '`physio`', etc.).\n",
    "* `subject`: The `subject label`\n",
    "* `session`: The `session label`\n",
    "* `run`: The `run index`\n",
    "* `task`: The `task name`\n",
    "\n",
    "New `entities` are continually being defined as the spec grows, and in principle (though not always in practice), `PyBIDS` should be aware of all `entities` that are defined in the `BIDS` specification.\n",
    "\n",
    "### Filtering by metadata\n",
    "\n",
    "All of the entities listed above are found in the names of `BIDS` files. But sometimes we want to search for files based not just on their names, but also based on `metadata` defined (per the `BIDS` specification) in `JSON` files. Fortunately for us, when we initialize a `BIDSLayout`, all `metadata files` associated with `BIDS files` are automatically indexed. This means we can pass any key that occurs in any `JSON file` in our project as an argument to `.get()`. We can combine these with any number of core `BIDS` `entities` (like `subject`, `run`, etc.).\n",
    "\n",
    "For example, say we want to retrieve all files where (a)  `acquisition` type is `'prefrontal'`, and (b) the subject is `'01'` or `'02'`. Here's how we can do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<BIDSImageFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/func/sub-01_ses-1_task-rest_acq-prefrontal_bold.nii.gz'>,\n",
       " <BIDSDataFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-1/func/sub-01_ses-1_task-rest_acq-prefrontal_physio.tsv.gz'>,\n",
       " <BIDSImageFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-2/func/sub-01_ses-2_task-rest_acq-prefrontal_bold.nii.gz'>,\n",
       " <BIDSDataFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01/ses-2/func/sub-01_ses-2_task-rest_acq-prefrontal_physio.tsv.gz'>,\n",
       " <BIDSImageFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-02/ses-1/func/sub-02_ses-1_task-rest_acq-prefrontal_bold.nii.gz'>,\n",
       " <BIDSDataFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-02/ses-1/func/sub-02_ses-1_task-rest_acq-prefrontal_physio.tsv.gz'>,\n",
       " <BIDSImageFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-02/ses-2/func/sub-02_ses-2_task-rest_acq-prefrontal_bold.nii.gz'>,\n",
       " <BIDSDataFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-02/ses-2/func/sub-02_ses-2_task-rest_acq-prefrontal_physio.tsv.gz'>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.get(subject=['01', '02'], acquisition = 'prefrontal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we passed a list in for `subject` rather than just a string. This principle applies to all filters: you can always pass in a list instead of a single value, and this will be interpreted as a logical disjunction (i.e., a file must match any one of the provided values).\n",
    "\n",
    "### Other `return_type` values\n",
    "While we'll typically want to work with either `BIDSFile` objects or filenames, we can also ask `get()` to return unique values (or ids) of particular entities. For example, say we want to know which subjects have at least one `T1w` file. We can request that information by setting `return_type='id'`. When using this option, we also need to specify a target entity (or metadata keyword) called `target`. This combination tells the `BIDSLayout` to return the unique values for the specified `target` entity. For example, in the next example, we ask for all of the unique subject IDs that have at least one file with a `T1w` suffix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:05:23.964766Z",
     "start_time": "2018-08-01T20:05:23.957477Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask get() to return the ids of subjects that have T1w files\n",
    "layout.get(return_type='id', target='subject', suffix='T1w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our `target` is a `BIDS` entity that corresponds to a particular directory in the `BIDS` spec (e.g., `subject` or `session`) we can also use `return_type='dir'` to get all matching subdirectories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:05:23.983125Z",
     "start_time": "2018-08-01T20:05:23.975085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-01',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-02',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-03',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-04',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-05',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-06',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-07',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-08',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-09',\n",
       " '/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_7t_trt/sub-10']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.get(return_type='dir', target='subject')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other `get()` options\n",
    "The `.get()` method has a number of other useful arguments that control its behavior. We won't discuss these in detail here, but briefly, here are a couple worth knowing about:\n",
    "* regex_search: If you set this to `True`, string filter argument values will be interpreted as regular expressions.\n",
    "* scope: If your BIDS dataset contains BIDS-derivatives sub-datasets, you can specify where you wa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `BIDSFile`\n",
    "When you call `.get()` on a `BIDSLayout`, the default returned values are objects of class `BIDSFile`. A `BIDSFile` is a lightweight container for individual files in a BIDS dataset. It provides easy access to a variety of useful attributes and methods. Let's take a closer look. First, let's pick a random file from our existing `layout`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:05:23.926278Z",
     "start_time": "2018-08-01T20:05:23.741189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BIDSDataFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_synthetic/sub-01/ses-01/func/sub-01_ses-01_task-nback_run-01_stim.tsv.gz'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = BIDSLayout('../data/pybids_synthetic/')\n",
    "\n",
    "# Pick the 15th file in the dataset\n",
    "bf = layout.get()[15]\n",
    "\n",
    "# Print it\n",
    "bf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some of the attributes and methods available to us in a `BIDSFile` (note that some of these are only available for certain subclasses of `BIDSFile`; e.g., you can't call `get_image()` on a `BIDSFile` that doesn't correspond to an image file!):\n",
    "* `.path`: The full path of the associated file\n",
    "* `.filename`: The associated file's filename (without directory)\n",
    "* `.dirname`: The directory containing the file\n",
    "* `.get_entities()`: Returns information about entities associated with this `BIDSFile` (optionally including metadata)\n",
    "* `.get_image()`: Returns the file contents as a nibabel image (only works for image files)\n",
    "* `.get_df()`: Get file contents as a pandas DataFrame (only works for TSV files)\n",
    "* `.get_metadata()`: Returns a dictionary of all metadata found in associated JSON files\n",
    "* `.get_associations()`: Returns a list of all files associated with this one in some way\n",
    "\n",
    "Let's see some of these in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datatype': 'func',\n",
       " 'extension': '.tsv.gz',\n",
       " 'run': 01,\n",
       " 'session': '01',\n",
       " 'subject': '01',\n",
       " 'suffix': 'stim',\n",
       " 'task': 'nback'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print all the entities associated with this file, and their values\n",
    "bf.get_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Columns': ['stimA', 'stimB'], 'SamplingFrequency': 2.0, 'StartTime': 0.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print all the metadata associated with this file\n",
    "bf.get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Columns': ['stimA', 'stimB'],\n",
       " 'SamplingFrequency': 2.0,\n",
       " 'StartTime': 0.0,\n",
       " 'datatype': 'func',\n",
       " 'extension': '.tsv.gz',\n",
       " 'run': 01,\n",
       " 'session': '01',\n",
       " 'subject': '01',\n",
       " 'suffix': 'stim',\n",
       " 'task': 'nback'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can the union of both of the above in one shot like this\n",
    "bf.get_entities(metadata='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all the files associated with our target file in some way. Notice how we get back both the JSON sidecar for our target file, and the BOLD run that our target file contains physiological recordings for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<BIDSJSONFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_synthetic/task-nback_stim.json'>,\n",
       " <BIDSImageFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_synthetic/sub-01/ses-01/func/sub-01_ses-01_task-nback_run-01_bold.nii'>,\n",
       " <BIDSImageFile filename='/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_synthetic/sub-01/ses-01/func/sub-01_ses-01_task-nback_run-01_bold.nii.gz'>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf.get_associations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In cases where a file has a `.tsv.gz` or `.tsv` extension, it will automatically be created as a `BIDSDataFile`, and we can easily grab the contents as a pandas `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>respiratory</th>\n",
       "      <th>cardiac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.714844</td>\n",
       "      <td>-0.262109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.757342</td>\n",
       "      <td>0.048933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.796851</td>\n",
       "      <td>0.355185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.833215</td>\n",
       "      <td>0.626669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.866291</td>\n",
       "      <td>0.836810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   onset  respiratory   cardiac\n",
       "0    0.0    -0.714844 -0.262109\n",
       "1    0.1    -0.757342  0.048933\n",
       "2    0.2    -0.796851  0.355185\n",
       "3    0.3    -0.833215  0.626669\n",
       "4    0.4    -0.866291  0.836810"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first physiological recording file\n",
    "recfile = layout.get(suffix='physio')[0]\n",
    "\n",
    "# Get contents as a DataFrame and show the first few rows\n",
    "df = recfile.get_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it would have been easy enough to read the contents of the file ourselves with pandas' `read_csv()` method, notice that in the above example, `get_df()` saved us the trouble of having to read the physiological recording file's metadata, pull out the column names and sampling rate, and add timing information.\n",
    "\n",
    "Mind you, if we don't *want* the timing information, we can ignore it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respiratory</th>\n",
       "      <th>cardiac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.714844</td>\n",
       "      <td>-0.262109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.757342</td>\n",
       "      <td>0.048933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.796851</td>\n",
       "      <td>0.355185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.833215</td>\n",
       "      <td>0.626669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.866291</td>\n",
       "      <td>0.836810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   respiratory   cardiac\n",
       "0    -0.714844 -0.262109\n",
       "1    -0.757342  0.048933\n",
       "2    -0.796851  0.355185\n",
       "3    -0.833215  0.626669\n",
       "4    -0.866291  0.836810"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recfile.get_df(include_timing=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other utilities\n",
    "\n",
    "### Filename parsing\n",
    "Say you have a filename, and you want to manually extract BIDS entities from it. The `parse_file_entities` method provides the facility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:05:24.035216Z",
     "start_time": "2018-08-01T20:05:24.030080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': '01', 'run': 1, 'suffix': 'T2w', 'extension': '.nii.gz'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/a/fake/path/to/a/BIDS/file/sub-01_run-1_T2w.nii.gz\"\n",
    "layout.parse_file_entities(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path construction\n",
    "You may want to create valid BIDS filenames for files that are new or hypothetical that would sit within your BIDS project. This is useful when you know what entity values you need to write out to, but don't want to deal with looking up the precise BIDS file-naming syntax. In the example below, imagine we've created a new file containing stimulus presentation information, and we want to save it to a `.tsv.gz` file, per the BIDS naming conventions. All we need to do is define a dictionary with the name components, and `build_path` takes care of the rest (including injecting sub-directories!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:05:24.049418Z",
     "start_time": "2018-08-01T20:05:24.044544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_synthetic/sub-01/func/sub-01_task-nback_run-2_bold.nii.gz'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = {\n",
    "    'subject': '01',\n",
    "    'run': 2,\n",
    "    'task': 'nback',\n",
    "    'suffix': 'bold'\n",
    "}\n",
    "\n",
    "layout.build_path(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:05:24.064220Z",
     "start_time": "2018-08-01T20:05:24.058906Z"
    }
   },
   "source": [
    "You can also use `build_path` in more sophisticated waysâ€”for example, by defining your own set of matching templates that cover cases not supported by BIDS out of the box. For example, suppose you want to create a template for naming a new z-stat file. You could do something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/peerherholz/google_drive/GitHub/workshop_IRTG2150/workshop/advanced/../data/pybids_synthetic/sub-01_task-n-back_run-2_z.nii.gz'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NBVAL_SKIP\n",
    "# Define the pattern to build out of the components passed in the dictionary\n",
    "pattern = \"sub-{subject}[_ses-{session}]_task-{task}[_acq-{acquisition}][_rec-{reconstruction}][_run-{run}][_echo-{echo}]_{suffix<z>}.nii.gz\",\n",
    "\n",
    "entities = {\n",
    "    'subject': '01',\n",
    "    'run': 2,\n",
    "    'task': 'n-back',\n",
    "    'suffix': 'z'\n",
    "}\n",
    "\n",
    "# Notice we pass the new pattern as the second argument\n",
    "layout.build_path(entities, pattern, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting a `BIDSLayout` to a pandas `Dataframe`\n",
    "If you want a summary of all the files in your `BIDSLayout`, but don't want to have to iterate `BIDSFile` objects and extract their entities, you can get a nice bird's-eye view of your dataset using the `to_df()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:05:24.275066Z",
     "start_time": "2018-08-01T20:05:24.248179Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>entity</th>\n",
       "      <th>path</th>\n",
       "      <th>datatype</th>\n",
       "      <th>extension</th>\n",
       "      <th>fmap</th>\n",
       "      <th>run</th>\n",
       "      <th>scans</th>\n",
       "      <th>session</th>\n",
       "      <th>subject</th>\n",
       "      <th>suffix</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/peerherholz/google_drive/GitHub/worksho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T1w</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/peerherholz/google_drive/GitHub/worksho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>description</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/peerherholz/google_drive/GitHub/worksho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dwi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/peerherholz/google_drive/GitHub/worksho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.tsv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>participants</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/peerherholz/google_drive/GitHub/worksho...</td>\n",
       "      <td>anat</td>\n",
       "      <td>.nii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>T1w</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "entity                                               path datatype extension  \\\n",
       "0       /Users/peerherholz/google_drive/GitHub/worksho...      NaN     .json   \n",
       "1       /Users/peerherholz/google_drive/GitHub/worksho...      NaN     .json   \n",
       "2       /Users/peerherholz/google_drive/GitHub/worksho...      NaN     .json   \n",
       "3       /Users/peerherholz/google_drive/GitHub/worksho...      NaN      .tsv   \n",
       "4       /Users/peerherholz/google_drive/GitHub/worksho...     anat      .nii   \n",
       "\n",
       "entity fmap  run scans session subject        suffix task  \n",
       "0       NaN  NaN   NaN     NaN     NaN           T1w  NaN  \n",
       "1       NaN  NaN   NaN     NaN     NaN   description  NaN  \n",
       "2       NaN  NaN   NaN     NaN     NaN           dwi  NaN  \n",
       "3       NaN  NaN   NaN     NaN     NaN  participants  NaN  \n",
       "4       NaN  NaN   NaN      01      01           T1w  NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the layout to a pandas dataframe\n",
    "df = layout.to_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also include metadata in the result if we like (which may blow up our `DataFrame` if we have a large dataset). Note that in this case, most of our cells will have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>entity</th>\n",
       "      <th>path</th>\n",
       "      <th>Columns</th>\n",
       "      <th>EchoTime</th>\n",
       "      <th>EchoTime1</th>\n",
       "      <th>EchoTime2</th>\n",
       "      <th>EffectiveEchoSpacing</th>\n",
       "      <th>FlipAngle</th>\n",
       "      <th>IntendedFor</th>\n",
       "      <th>PhaseEncodingDirection</th>\n",
       "      <th>RepetitionTime</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalReadoutTime</th>\n",
       "      <th>datatype</th>\n",
       "      <th>extension</th>\n",
       "      <th>fmap</th>\n",
       "      <th>run</th>\n",
       "      <th>scans</th>\n",
       "      <th>session</th>\n",
       "      <th>subject</th>\n",
       "      <th>suffix</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/peerherholz/google_drive/GitHub/worksho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T1w</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/peerherholz/google_drive/GitHub/worksho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>description</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/peerherholz/google_drive/GitHub/worksho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dwi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/peerherholz/google_drive/GitHub/worksho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.tsv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>participants</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/peerherholz/google_drive/GitHub/worksho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anat</td>\n",
       "      <td>.nii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>T1w</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "entity                                               path Columns EchoTime  \\\n",
       "0       /Users/peerherholz/google_drive/GitHub/worksho...     NaN      NaN   \n",
       "1       /Users/peerherholz/google_drive/GitHub/worksho...     NaN      NaN   \n",
       "2       /Users/peerherholz/google_drive/GitHub/worksho...     NaN      NaN   \n",
       "3       /Users/peerherholz/google_drive/GitHub/worksho...     NaN      NaN   \n",
       "4       /Users/peerherholz/google_drive/GitHub/worksho...     NaN   0.0029   \n",
       "\n",
       "entity EchoTime1 EchoTime2 EffectiveEchoSpacing FlipAngle IntendedFor  \\\n",
       "0            NaN       NaN                  NaN       NaN         NaN   \n",
       "1            NaN       NaN                  NaN       NaN         NaN   \n",
       "2            NaN       NaN                  NaN       NaN         NaN   \n",
       "3            NaN       NaN                  NaN       NaN         NaN   \n",
       "4            NaN       NaN                  NaN         8         NaN   \n",
       "\n",
       "entity PhaseEncodingDirection RepetitionTime  ... TotalReadoutTime datatype  \\\n",
       "0                         NaN            NaN  ...              NaN      NaN   \n",
       "1                         NaN            NaN  ...              NaN      NaN   \n",
       "2                         NaN            NaN  ...              NaN      NaN   \n",
       "3                         NaN            NaN  ...              NaN      NaN   \n",
       "4                         NaN            2.5  ...              NaN     anat   \n",
       "\n",
       "entity extension fmap  run scans session subject        suffix task  \n",
       "0          .json  NaN  NaN   NaN     NaN     NaN           T1w  NaN  \n",
       "1          .json  NaN  NaN   NaN     NaN     NaN   description  NaN  \n",
       "2          .json  NaN  NaN   NaN     NaN     NaN           dwi  NaN  \n",
       "3           .tsv  NaN  NaN   NaN     NaN     NaN  participants  NaN  \n",
       "4           .nii  NaN  NaN   NaN      01      01           T1w  NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.to_df(metadata=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIDSValidator\n",
    "\n",
    "`pybids` implicitly imports a `BIDSValidator` class from the separate [`bids-validator`](https://github.com/bids-standard/bids-validator) package. You can use the `BIDSValidator` to determine whether a filepath is a valid BIDS filepath, as well as answering questions about what kind of data it represents. Note, however, that this implementation of the BIDS validator is *not* necessarily up-to-date with the JavaScript version available online. Moreover, the Python validator only tests individual files, and is currently unable to validate entire BIDS datasets. For that, you should use the [online BIDS validator](https://bids-standard.github.io/bids-validator/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:05:27.763448Z",
     "start_time": "2018-08-01T20:05:27.749652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bids import BIDSValidator\n",
    "\n",
    "# Note that when using the bids validator, the filepath MUST be relative to the top level bids directory\n",
    "validator = BIDSValidator()\n",
    "validator.is_bids('/sub-01/ses-test/anat/sub-01_ses-test_T1w.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:05:27.773052Z",
     "start_time": "2018-08-01T20:05:27.765263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can decide if a filepath represents a file part of the specification\n",
    "validator.is_file('/sub-01/ses-test/anat/sub-01_ses-test_T1w.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can check if file a dataset top\n",
    "validator.is_top_level('/dataset_description.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or subject (or session) level\n",
    "validator.is_subject_level('/dataset_description.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.is_session_level('/sub-01/ses-test/anat/sub-01_ses-test_T1w.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T20:05:27.780022Z",
     "start_time": "2018-08-01T20:05:27.775281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can decide if a filepath represents phenotypic data\n",
    "validator.is_phenotypic('/sub-01/ses-test/anat/sub-01_ses-test_T1w.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report generation\n",
    "`PyBIDS` also allows you to automatically create data acquisition reports based on the available `image` and `meta-data` information. Comparable to functionality in e.g. [fMRIPrep](https://fmriprep.org/en/stable/citing.html?highlight=boilerplate) this enables a new level of standardization and subsequent advancements (transparency, FAIR-ness, meta-analyses, etc.). Let's import the `BIDSReport` function from the `reports` submodule and initiate a `BIDS` dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bids.reports import BIDSReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we only need to apply the `BIDSReport` function to our `layout` and generate our report. (We'll get some warnings as the example data set is missing some parts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patterns detected: 1\n",
      "Remember to double-check everything and to replace <deg> with a degree symbol.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "report = BIDSReport(layout)\n",
    "\n",
    "counter = report.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, one pattern was detected and we can evaluate the actual corresponding information, that is our `report`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In session 01, MR data were acquired using a UNKNOWN-Tesla MANUFACTURER MODEL MRI scanner.\n",
      "\tOne run of T1-weighted   single-echo structural MRI data were collected (256 slices; repetition time, TR=2500ms; echo time, TE=2.9ms; flip angle, FA=8<deg>; field of view, FOV=256x256mm; matrix size=256x256; voxel size=1x1x1mm).\n",
      "\tOne run of T1-weighted   single-echo structural MRI data were collected (256 slices; repetition time, TR=2500ms; echo time, TE=2.9ms; flip angle, FA=8<deg>; field of view, FOV=256x256mm; matrix size=256x256; voxel size=1x1x1mm).\n",
      "\tOne run of   diffusion-weighted (dMRI) data were collected (repetition time, TR=8400ms; echo time, TE=90ms; flip angle, FA=90<deg>; field of view, FOV=128x128mm; voxel size=2x2x2mm; matrix size=64x64; b-values of 0 and 1000 acquired; 64 diffusion directions).\n",
      "\tA   field map (phase encoding: anterior to posterior; 256 slices; repetition time, TR=400ms; echo time 1 / 2, TE1/2=5190007.65ms; flip angle, FA=60.0<deg>; field of view, FOV=256x256mm; matrix size=256x256; voxel size=1x1x1mm) was acquired for the first and second runs of the N-Back BOLD scan.\n",
      "\tTwo runs of N-Back   single-echo fMRI data were collected (64 slices; repetition time, TR=2500ms; echo time, TE=30ms; flip angle, FA=UNKNOWN<deg>; field of view, FOV=128x128mm; matrix size=64x64; voxel size=2x2x2mm). Run duration was 2:40 minutes, during which 64 volumes were acquired.\n",
      "\tTwo runs of N-Back   single-echo fMRI data were collected (64 slices; repetition time, TR=2500ms; echo time, TE=30ms; flip angle, FA=UNKNOWN<deg>; field of view, FOV=128x128mm; matrix size=64x64; voxel size=2x2x2mm). Run duration was 2:40 minutes, during which 64 volumes were acquired.\n",
      "\tOne run of Rest   single-echo fMRI data were collected (64 slices; repetition time, TR=2500ms; echo time, TE=30ms; flip angle, FA=UNKNOWN<deg>; field of view, FOV=128x128mm; matrix size=64x64; voxel size=2x2x2mm). Run duration was 2:40 minutes, during which 64 volumes were acquired.\n",
      "\tOne run of Rest   single-echo fMRI data were collected (64 slices; repetition time, TR=2500ms; echo time, TE=30ms; flip angle, FA=UNKNOWN<deg>; field of view, FOV=128x128mm; matrix size=64x64; voxel size=2x2x2mm). Run duration was 2:40 minutes, during which 64 volumes were acquired.\n",
      "\tOne run of T1-weighted   single-echo structural MRI data were collected (256 slices; repetition time, TR=2500ms; echo time, TE=2.9ms; flip angle, FA=8<deg>; field of view, FOV=256x256mm; matrix size=256x256; voxel size=1x1x1mm).\n",
      "\tOne run of T1-weighted   single-echo structural MRI data were collected (256 slices; repetition time, TR=2500ms; echo time, TE=2.9ms; flip angle, FA=8<deg>; field of view, FOV=256x256mm; matrix size=256x256; voxel size=1x1x1mm).\n",
      "\tTwo runs of N-Back   single-echo fMRI data were collected (64 slices; repetition time, TR=2500ms; echo time, TE=30ms; flip angle, FA=UNKNOWN<deg>; field of view, FOV=128x128mm; matrix size=64x64; voxel size=2x2x2mm). Run duration was 2:40 minutes, during which 64 volumes were acquired.\n",
      "\tTwo runs of N-Back   single-echo fMRI data were collected (64 slices; repetition time, TR=2500ms; echo time, TE=30ms; flip angle, FA=UNKNOWN<deg>; field of view, FOV=128x128mm; matrix size=64x64; voxel size=2x2x2mm). Run duration was 2:40 minutes, during which 64 volumes were acquired.\n",
      "\tOne run of Rest   single-echo fMRI data were collected (64 slices; repetition time, TR=2500ms; echo time, TE=30ms; flip angle, FA=UNKNOWN<deg>; field of view, FOV=128x128mm; matrix size=64x64; voxel size=2x2x2mm). Run duration was 2:40 minutes, during which 64 volumes were acquired.\n",
      "\tOne run of Rest   single-echo fMRI data were collected (64 slices; repetition time, TR=2500ms; echo time, TE=30ms; flip angle, FA=UNKNOWN<deg>; field of view, FOV=128x128mm; matrix size=64x64; voxel size=2x2x2mm). Run duration was 2:40 minutes, during which 64 volumes were acquired.\n",
      "\tIn session 02, MR data were acquired using a UNKNOWN-Tesla MANUFACTURER MODEL MRI scanner.\n",
      "\tOne run of T1-weighted   single-echo structural MRI data were collected (256 slices; repetition time, TR=2500ms; echo time, TE=2.9ms; flip angle, FA=8<deg>; field of view, FOV=256x256mm; matrix size=256x256; voxel size=1x1x1mm).\n",
      "\tOne run of T1-weighted   single-echo structural MRI data were collected (256 slices; repetition time, TR=2500ms; echo time, TE=2.9ms; flip angle, FA=8<deg>; field of view, FOV=256x256mm; matrix size=256x256; voxel size=1x1x1mm).\n",
      "\tOne run of   diffusion-weighted (dMRI) data were collected (repetition time, TR=8400ms; echo time, TE=90ms; flip angle, FA=90<deg>; field of view, FOV=128x128mm; voxel size=2x2x2mm; matrix size=64x64; b-values of 0 and 1000 acquired; 64 diffusion directions).\n",
      "\tA   field map (phase encoding: anterior to posterior; 256 slices; repetition time, TR=400ms; echo time 1 / 2, TE1/2=5190007.65ms; flip angle, FA=60.0<deg>; field of view, FOV=256x256mm; matrix size=256x256; voxel size=1x1x1mm) was acquired for the first and second runs of the N-Back BOLD scan.\n",
      "\tTwo runs of N-Back   single-echo fMRI data were collected (64 slices; repetition time, TR=2500ms; echo time, TE=30ms; flip angle, FA=UNKNOWN<deg>; field of view, FOV=128x128mm; matrix size=64x64; voxel size=2x2x2mm). Run duration was 2:40 minutes, during which 64 volumes were acquired.\n",
      "\tTwo runs of N-Back   single-echo fMRI data were collected (64 slices; repetition time, TR=2500ms; echo time, TE=30ms; flip angle, FA=UNKNOWN<deg>; field of view, FOV=128x128mm; matrix size=64x64; voxel size=2x2x2mm). Run duration was 2:40 minutes, during which 64 volumes were acquired.\n",
      "\tOne run of Rest   single-echo fMRI data were collected (64 slices; repetition time, TR=2500ms; echo time, TE=30ms; flip angle, FA=UNKNOWN<deg>; field of view, FOV=128x128mm; matrix size=64x64; voxel size=2x2x2mm). Run duration was 2:40 minutes, during which 64 volumes were acquired.\n",
      "\tOne run of Rest   single-echo fMRI data were collected (64 slices; repetition time, TR=2500ms; echo time, TE=30ms; flip angle, FA=UNKNOWN<deg>; field of view, FOV=128x128mm; matrix size=64x64; voxel size=2x2x2mm). Run duration was 2:40 minutes, during which 64 volumes were acquired.\n",
      "\tOne run of T1-weighted   single-echo structural MRI data were collected (256 slices; repetition time, TR=2500ms; echo time, TE=2.9ms; flip angle, FA=8<deg>; field of view, FOV=256x256mm; matrix size=256x256; voxel size=1x1x1mm).\n",
      "\tOne run of T1-weighted   single-echo structural MRI data were collected (256 slices; repetition time, TR=2500ms; echo time, TE=2.9ms; flip angle, FA=8<deg>; field of view, FOV=256x256mm; matrix size=256x256; voxel size=1x1x1mm).\n",
      "\tTwo runs of N-Back   single-echo fMRI data were collected (64 slices; repetition time, TR=2500ms; echo time, TE=30ms; flip angle, FA=UNKNOWN<deg>; field of view, FOV=128x128mm; matrix size=64x64; voxel size=2x2x2mm). Run duration was 2:40 minutes, during which 64 volumes were acquired.\n",
      "\tTwo runs of N-Back   single-echo fMRI data were collected (64 slices; repetition time, TR=2500ms; echo time, TE=30ms; flip angle, FA=UNKNOWN<deg>; field of view, FOV=128x128mm; matrix size=64x64; voxel size=2x2x2mm). Run duration was 2:40 minutes, during which 64 volumes were acquired.\n",
      "\tOne run of Rest   single-echo fMRI data were collected (64 slices; repetition time, TR=2500ms; echo time, TE=30ms; flip angle, FA=UNKNOWN<deg>; field of view, FOV=128x128mm; matrix size=64x64; voxel size=2x2x2mm). Run duration was 2:40 minutes, during which 64 volumes were acquired.\n",
      "\tOne run of Rest   single-echo fMRI data were collected (64 slices; repetition time, TR=2500ms; echo time, TE=30ms; flip angle, FA=UNKNOWN<deg>; field of view, FOV=128x128mm; matrix size=64x64; voxel size=2x2x2mm). Run duration was 2:40 minutes, during which 64 volumes were acquired.\n",
      "\n",
      "Dicoms were converted to NIfTI-1 format. This section was (in part) generated automatically using pybids (0.18.1).\n"
     ]
    }
   ],
   "source": [
    "main_report = counter.most_common()[0][0]\n",
    "print(main_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
